# To Do

## Current

- [ ] use CPack in CI to generate packages and publish
- [ ] improve token parser API with new codepoint semantics
- [ ] incorporate token parser change into parser
- [ ] rewrite the parser, it should be a state machine
    - [x] implement group parsing
    - [x] implement set parsing
    - [x] implement set range parsing
    - [x] implement repeat parsing
    - [ ] implement escape handling
    - [ ] implement special character handling
- [ ] json generation for all data structures (autogenerated with pycparser?)
- [ ] remove legacy code
- [ ] add or think about memory handling
- [ ] remove normal_escaped handling
- [ ] adapt generation for new data structures
- [ ] write benchmark for new parser
- [ ] try changing parser state stack to linked list?
- [ ] implement stack depth limiting for new parser (as separate method)
- [ ] squash compiler warnings
    - [x] get rid of easy ones
    - [ ] get rid of all
- [ ] implement code profiling
- [ ] implement static analysis (linter, clang-tidy?)
- [ ] fix debug build on alpine
- [x] fix include-what-you-use recommendations
- [x] add check target to see if library exports any symbols that are not
    prefixed with *passgen* and perhaps one to check if it exports any defines
    that aren't prefixed with *PASSGEN*.
- [x] implement include-what-you-use
- [x] change token parser to merge codepoint and escaped members
- [x] remove useless enums from token parser
- [x] remove or disable non-deterministic tests (made tests deterministic)
- [x] add pseudorandom number generation to randomness
- [x] add ~~cldoc~~ doxygen documentation output to build system (why not cldoc? unmaintained, unfortunately).
- [x] publish doxygen documentation in CI
- [x] add code coverage generation to CI system
- [x] write or enable benchmarks for random API to check performance
- [x] change random object to have just a buffer and a pointer to a function
    used to fill the buffer again (to allow the use of different backends).
- [x] enable memory sanitizer for tests
- [x] move all `include/passgen/pattern/*.h` data structures into `include/passgen/data/`.
- [x] rewrite the token parser. it should be a state machine
- [x] test list autogeneration (done in `scripts/tests_generate.rb`)
- [x] enum mapping autogeneration (done in `scripts/generate_enum_mapping.rb`)
- [x] rename array to queue or stack
    - [x] move all uses of array over to stack
- [x] implement type specialisations for array data type
- [x] implement code coverage generation
- [x] implement automatic code formatting
- [x] implement sanitizer support
- [x] make generation code work with new parser and data structures

## Ideas

- Unity build (better optimisation)
- Link-time optimisation
- CPack generate tarball, debian package, etc.

- rewrite the passgen parser to use batched operations, meaning that all
  all unicode should be parsed in one go, then all (or 128) tokens should
  be parsed at a time. but still allow it to be used in a streaming manner.
  this should be more optimal for speed and also just lead to cleaner code.
- make the data structures pretty. they should be maintainable, and optionally
  allow for JSON output for debugging
- write benchmarks to make sure that the parser is quick. that's the whole
  reason this is written in C, anyways.
- write a fuzzing backend, using AFL or the like, to ensure there are no bugs
  that can crash the parser.
- optimise the testing system, perhaps use another testing framework that is
  more actively maintained, test more edge cases and use macros to write clean
  tests.
- implement wordlist functionality (find a space-efficient way to store large
  word lists?)
